{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20e4602a",
   "metadata": {},
   "source": [
    "Word Embedding techniques "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3227593e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kousimon\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re \n",
    "import spacy \n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "import torch\n",
    "import torchtext\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from torchtext.vocab import GloVe\n",
    "from torchtext.vocab import Vectors\n",
    "from transformers import BertTokenizer,BertModel\n",
    "from tqdm import tqdm\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5d490fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"nlp_sentences_50.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "218de0dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Natural Language Processing is evolving fast.\n",
       "1       NLP helps computers understand human language.\n",
       "2            Text classification is a key task in NLP.\n",
       "3    Tokenization is the first step in most NLP pip...\n",
       "4           Stemming reduces words to their root form.\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d018e7f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Natural Language Processing is evolving fast.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NLP helps computers understand human language.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Text classification is a key task in NLP.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tokenization is the first step in most NLP pip...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stemming reduces words to their root form.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0      Natural Language Processing is evolving fast.\n",
       "1     NLP helps computers understand human language.\n",
       "2          Text classification is a key task in NLP.\n",
       "3  Tokenization is the first step in most NLP pip...\n",
       "4         Stemming reduces words to their root form."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "if 'text' not in df.columns:\n",
    "    raise ValueError(\"The DataFrame does not contain a 'text' column.\")\n",
    "\n",
    "def clean_and_tokenize(text):\n",
    "    cleaned = re.sub(r'[^a-zA-Z0-9\\s]', ' ', str(text).lower())\n",
    "    doc = nlp(cleaned)\n",
    "    return [token.text for token in doc if not token.is_space and token.text not in STOP_WORDS]\n",
    "\n",
    "def clean_and_tokenize_pos(text):\n",
    "    cleaned = re.sub(r'^a-zA-Z',' ',str(text).lower())\n",
    "    doc = nlp(cleaned)\n",
    "    return [(token.text,token.pos_) for token in doc if not token.is_space and token.text not in STOP_WORDS]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1d84a38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>POS_Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Natural Language Processing is evolving fast.</td>\n",
       "      <td>[natural, language, processing, evolving, fast]</td>\n",
       "      <td>[(natural, ADJ), (language, NOUN), (processing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NLP helps computers understand human language.</td>\n",
       "      <td>[nlp, helps, computers, understand, human, lan...</td>\n",
       "      <td>[(nlp, PROPN), (helps, VERB), (computers, NOUN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Text classification is a key task in NLP.</td>\n",
       "      <td>[text, classification, key, task, nlp]</td>\n",
       "      <td>[(text, NOUN), (classification, NOUN), (key, A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tokenization is the first step in most NLP pip...</td>\n",
       "      <td>[tokenization, step, nlp, pipelines]</td>\n",
       "      <td>[(tokenization, NOUN), (step, NOUN), (nlp, PRO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stemming reduces words to their root form.</td>\n",
       "      <td>[stemming, reduces, words, root, form]</td>\n",
       "      <td>[(stemming, NOUN), (reduces, VERB), (words, NO...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0      Natural Language Processing is evolving fast.   \n",
       "1     NLP helps computers understand human language.   \n",
       "2          Text classification is a key task in NLP.   \n",
       "3  Tokenization is the first step in most NLP pip...   \n",
       "4         Stemming reduces words to their root form.   \n",
       "\n",
       "                                              tokens  \\\n",
       "0    [natural, language, processing, evolving, fast]   \n",
       "1  [nlp, helps, computers, understand, human, lan...   \n",
       "2             [text, classification, key, task, nlp]   \n",
       "3               [tokenization, step, nlp, pipelines]   \n",
       "4             [stemming, reduces, words, root, form]   \n",
       "\n",
       "                                             POS_Tag  \n",
       "0  [(natural, ADJ), (language, NOUN), (processing...  \n",
       "1  [(nlp, PROPN), (helps, VERB), (computers, NOUN...  \n",
       "2  [(text, NOUN), (classification, NOUN), (key, A...  \n",
       "3  [(tokenization, NOUN), (step, NOUN), (nlp, PRO...  \n",
       "4  [(stemming, NOUN), (reduces, VERB), (words, NO...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tokens'] = df['text'].apply(clean_and_tokenize)\n",
    "df['POS_Tag'] = df['text'].apply(clean_and_tokenize_pos)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19cea692",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>activation</th>\n",
       "      <th>affects</th>\n",
       "      <th>ai</th>\n",
       "      <th>algorithm</th>\n",
       "      <th>algorithms</th>\n",
       "      <th>analysis</th>\n",
       "      <th>artificial</th>\n",
       "      <th>autoencoders</th>\n",
       "      <th>automate</th>\n",
       "      <th>...</th>\n",
       "      <th>understand</th>\n",
       "      <th>understanding</th>\n",
       "      <th>unsupervised</th>\n",
       "      <th>uses</th>\n",
       "      <th>validation</th>\n",
       "      <th>values</th>\n",
       "      <th>visualization</th>\n",
       "      <th>word</th>\n",
       "      <th>words</th>\n",
       "      <th>world</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 156 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  activation  affects  ai  algorithm  algorithms  analysis  \\\n",
       "0         0           0        0   0          0           0         0   \n",
       "1         0           0        0   0          0           0         0   \n",
       "2         0           0        0   0          0           0         0   \n",
       "3         0           0        0   0          0           0         0   \n",
       "4         0           0        0   0          0           0         0   \n",
       "\n",
       "   artificial  autoencoders  automate  ...  understand  understanding  \\\n",
       "0           0             0         0  ...           0              0   \n",
       "1           0             0         0  ...           1              0   \n",
       "2           0             0         0  ...           0              0   \n",
       "3           0             0         0  ...           0              0   \n",
       "4           0             0         0  ...           0              0   \n",
       "\n",
       "   unsupervised  uses  validation  values  visualization  word  words  world  \n",
       "0             0     0           0       0              0     0      0      0  \n",
       "1             0     0           0       0              0     0      0      0  \n",
       "2             0     0           0       0              0     0      0      0  \n",
       "3             0     0           0       0              0     0      0      0  \n",
       "4             0     0           0       0              0     0      1      0  \n",
       "\n",
       "[5 rows x 156 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## ONE HOT ENCODING\n",
    "\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "one_hot = mlb.fit_transform(df['tokens'])\n",
    "\n",
    "one_hot_df = pd.DataFrame(one_hot,columns = mlb.classes_)\n",
    "one_hot_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7cf2839a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>activation</th>\n",
       "      <th>affects</th>\n",
       "      <th>ai</th>\n",
       "      <th>algorithm</th>\n",
       "      <th>algorithms</th>\n",
       "      <th>analysis</th>\n",
       "      <th>artificial</th>\n",
       "      <th>autoencoders</th>\n",
       "      <th>automate</th>\n",
       "      <th>...</th>\n",
       "      <th>understand</th>\n",
       "      <th>understanding</th>\n",
       "      <th>unsupervised</th>\n",
       "      <th>uses</th>\n",
       "      <th>validation</th>\n",
       "      <th>values</th>\n",
       "      <th>visualization</th>\n",
       "      <th>word</th>\n",
       "      <th>words</th>\n",
       "      <th>world</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 156 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  activation  affects  ai  algorithm  algorithms  analysis  \\\n",
       "0         0           0        0   0          0           0         0   \n",
       "1         0           0        0   0          0           0         0   \n",
       "2         0           0        0   0          0           0         0   \n",
       "3         0           0        0   0          0           0         0   \n",
       "4         0           0        0   0          0           0         0   \n",
       "\n",
       "   artificial  autoencoders  automate  ...  understand  understanding  \\\n",
       "0           0             0         0  ...           0              0   \n",
       "1           0             0         0  ...           1              0   \n",
       "2           0             0         0  ...           0              0   \n",
       "3           0             0         0  ...           0              0   \n",
       "4           0             0         0  ...           0              0   \n",
       "\n",
       "   unsupervised  uses  validation  values  visualization  word  words  world  \n",
       "0             0     0           0       0              0     0      0      0  \n",
       "1             0     0           0       0              0     0      0      0  \n",
       "2             0     0           0       0              0     0      0      0  \n",
       "3             0     0           0       0              0     0      0      0  \n",
       "4             0     0           0       0              0     0      1      0  \n",
       "\n",
       "[5 rows x 156 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## BAG OF WORDS \n",
    "\n",
    "text = [' '.join(tokens) for tokens in df['tokens']]\n",
    "vec = CountVectorizer()\n",
    "bow = vec.fit_transform(text)\n",
    "bow_df = pd.DataFrame(bow.toarray(),columns = vec.get_feature_names_out())\n",
    "bow_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af65328b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>activation</th>\n",
       "      <th>affects</th>\n",
       "      <th>ai</th>\n",
       "      <th>algorithm</th>\n",
       "      <th>algorithms</th>\n",
       "      <th>analysis</th>\n",
       "      <th>artificial</th>\n",
       "      <th>autoencoders</th>\n",
       "      <th>automate</th>\n",
       "      <th>...</th>\n",
       "      <th>understand</th>\n",
       "      <th>understanding</th>\n",
       "      <th>unsupervised</th>\n",
       "      <th>uses</th>\n",
       "      <th>validation</th>\n",
       "      <th>values</th>\n",
       "      <th>visualization</th>\n",
       "      <th>word</th>\n",
       "      <th>words</th>\n",
       "      <th>world</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.438783</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.447214</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 156 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  activation  affects   ai  algorithm  algorithms  analysis  \\\n",
       "0       0.0         0.0      0.0  0.0        0.0         0.0       0.0   \n",
       "1       0.0         0.0      0.0  0.0        0.0         0.0       0.0   \n",
       "2       0.0         0.0      0.0  0.0        0.0         0.0       0.0   \n",
       "3       0.0         0.0      0.0  0.0        0.0         0.0       0.0   \n",
       "4       0.0         0.0      0.0  0.0        0.0         0.0       0.0   \n",
       "\n",
       "   artificial  autoencoders  automate  ...  understand  understanding  \\\n",
       "0         0.0           0.0       0.0  ...    0.000000            0.0   \n",
       "1         0.0           0.0       0.0  ...    0.438783            0.0   \n",
       "2         0.0           0.0       0.0  ...    0.000000            0.0   \n",
       "3         0.0           0.0       0.0  ...    0.000000            0.0   \n",
       "4         0.0           0.0       0.0  ...    0.000000            0.0   \n",
       "\n",
       "   unsupervised  uses  validation  values  visualization  word     words  \\\n",
       "0           0.0   0.0         0.0     0.0            0.0   0.0  0.000000   \n",
       "1           0.0   0.0         0.0     0.0            0.0   0.0  0.000000   \n",
       "2           0.0   0.0         0.0     0.0            0.0   0.0  0.000000   \n",
       "3           0.0   0.0         0.0     0.0            0.0   0.0  0.000000   \n",
       "4           0.0   0.0         0.0     0.0            0.0   0.0  0.447214   \n",
       "\n",
       "   world  \n",
       "0    0.0  \n",
       "1    0.0  \n",
       "2    0.0  \n",
       "3    0.0  \n",
       "4    0.0  \n",
       "\n",
       "[5 rows x 156 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "tfidf_mat = tfidf.fit_transform(text)\n",
    "tfidf_df = pd.DataFrame(tfidf_mat.toarray(),columns = tfidf.get_feature_names_out())\n",
    "tfidf_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b86c5ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "glove = Vectors(\n",
    "    name='glove.6B.100d.txt',\n",
    "    cache='C:/Users/Kousimon/Downloads/glove.6B'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e32fd9a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0817,  0.7159, -0.2068,  0.0296,  0.2303, -1.1452, -0.2969,  0.7235,\n",
      "         0.4237,  0.4391, -0.1736, -0.3742, -0.1118, -0.0814,  0.1779,  0.1807,\n",
      "         0.6416,  0.0766,  0.7338,  0.0568, -0.5870,  0.1979,  0.5395, -0.0841,\n",
      "        -0.3598,  0.0995,  0.4409,  0.4065, -0.2734,  0.4093, -0.5441,  0.3249,\n",
      "        -0.3346, -0.4434, -0.0139, -0.4158, -0.0713, -0.1875, -0.0526, -1.3428,\n",
      "         0.1466, -1.4384, -0.3564,  0.0761, -0.0038,  0.2221,  0.0268, -0.4826,\n",
      "         0.1124, -0.2780,  0.3645, -0.1440, -0.1794,  0.9890, -0.1420,  0.0271,\n",
      "        -0.6365, -0.6784,  2.2571, -0.0224,  0.1442,  0.1008,  0.5046, -0.2944,\n",
      "         0.2433, -0.0502,  0.3158, -0.4580,  0.6398, -0.0378, -0.7193,  0.6936,\n",
      "         0.4196, -0.1840,  0.6345,  0.4304, -0.3149,  0.1866, -0.4996,  0.6993,\n",
      "         0.8549,  0.3138, -1.0777,  0.5603, -1.8867,  0.7728,  1.3367, -0.7468,\n",
      "        -0.0777, -0.2813, -0.0960,  0.0701, -0.1414, -0.0486,  0.5042, -0.2826,\n",
      "         0.2881, -0.6854,  1.3961, -0.0686])\n"
     ]
    }
   ],
   "source": [
    "print(glove['processing'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac5174f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['glove_vectors'] = df['tokens'].apply(lambda x: [glove[word] for word in x if word in glove.stoi])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1bf6b582",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>POS_Tag</th>\n",
       "      <th>glove_vectors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Natural Language Processing is evolving fast.</td>\n",
       "      <td>[natural, language, processing, evolving, fast]</td>\n",
       "      <td>[(natural, ADJ), (language, NOUN), (processing...</td>\n",
       "      <td>[[tensor(0.4399), tensor(1.1951), tensor(0.702...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NLP helps computers understand human language.</td>\n",
       "      <td>[nlp, helps, computers, understand, human, lan...</td>\n",
       "      <td>[(nlp, PROPN), (helps, VERB), (computers, NOUN...</td>\n",
       "      <td>[[tensor(-0.4242), tensor(1.1379), tensor(-0.5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Text classification is a key task in NLP.</td>\n",
       "      <td>[text, classification, key, task, nlp]</td>\n",
       "      <td>[(text, NOUN), (classification, NOUN), (key, A...</td>\n",
       "      <td>[[tensor(-0.4970), tensor(0.7164), tensor(0.40...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tokenization is the first step in most NLP pip...</td>\n",
       "      <td>[tokenization, step, nlp, pipelines]</td>\n",
       "      <td>[(tokenization, NOUN), (step, NOUN), (nlp, PRO...</td>\n",
       "      <td>[[tensor(-0.3844), tensor(-0.1395), tensor(-0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stemming reduces words to their root form.</td>\n",
       "      <td>[stemming, reduces, words, root, form]</td>\n",
       "      <td>[(stemming, NOUN), (reduces, VERB), (words, NO...</td>\n",
       "      <td>[[tensor(0.7884), tensor(-0.2981), tensor(0.21...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0      Natural Language Processing is evolving fast.   \n",
       "1     NLP helps computers understand human language.   \n",
       "2          Text classification is a key task in NLP.   \n",
       "3  Tokenization is the first step in most NLP pip...   \n",
       "4         Stemming reduces words to their root form.   \n",
       "\n",
       "                                              tokens  \\\n",
       "0    [natural, language, processing, evolving, fast]   \n",
       "1  [nlp, helps, computers, understand, human, lan...   \n",
       "2             [text, classification, key, task, nlp]   \n",
       "3               [tokenization, step, nlp, pipelines]   \n",
       "4             [stemming, reduces, words, root, form]   \n",
       "\n",
       "                                             POS_Tag  \\\n",
       "0  [(natural, ADJ), (language, NOUN), (processing...   \n",
       "1  [(nlp, PROPN), (helps, VERB), (computers, NOUN...   \n",
       "2  [(text, NOUN), (classification, NOUN), (key, A...   \n",
       "3  [(tokenization, NOUN), (step, NOUN), (nlp, PRO...   \n",
       "4  [(stemming, NOUN), (reduces, VERB), (words, NO...   \n",
       "\n",
       "                                       glove_vectors  \n",
       "0  [[tensor(0.4399), tensor(1.1951), tensor(0.702...  \n",
       "1  [[tensor(-0.4242), tensor(1.1379), tensor(-0.5...  \n",
       "2  [[tensor(-0.4970), tensor(0.7164), tensor(0.40...  \n",
       "3  [[tensor(-0.3844), tensor(-0.1395), tensor(-0....  \n",
       "4  [[tensor(0.7884), tensor(-0.2981), tensor(0.21...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f4a02d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example dummy binary label: Even index -> class 0, Odd index -> class 1\n",
    "df['label'] = df.index % 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4bf329c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>POS_Tag</th>\n",
       "      <th>glove_vectors</th>\n",
       "      <th>glove_avg</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Natural Language Processing is evolving fast.</td>\n",
       "      <td>[natural, language, processing, evolving, fast]</td>\n",
       "      <td>[(natural, ADJ), (language, NOUN), (processing...</td>\n",
       "      <td>[[tensor(0.4399), tensor(1.1951), tensor(0.702...</td>\n",
       "      <td>[-0.003268391, 0.592868, 0.33463138, 0.2203791...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NLP helps computers understand human language.</td>\n",
       "      <td>[nlp, helps, computers, understand, human, lan...</td>\n",
       "      <td>[(nlp, PROPN), (helps, VERB), (computers, NOUN...</td>\n",
       "      <td>[[tensor(-0.4242), tensor(1.1379), tensor(-0.5...</td>\n",
       "      <td>[-0.031687822, 0.58213, 0.24518669, 0.05667926...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Text classification is a key task in NLP.</td>\n",
       "      <td>[text, classification, key, task, nlp]</td>\n",
       "      <td>[(text, NOUN), (classification, NOUN), (key, A...</td>\n",
       "      <td>[[tensor(-0.4970), tensor(0.7164), tensor(0.40...</td>\n",
       "      <td>[-0.43756, 0.5182328, 0.295148, -0.0667942, 0....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tokenization is the first step in most NLP pip...</td>\n",
       "      <td>[tokenization, step, nlp, pipelines]</td>\n",
       "      <td>[(tokenization, NOUN), (step, NOUN), (nlp, PRO...</td>\n",
       "      <td>[[tensor(-0.3844), tensor(-0.1395), tensor(-0....</td>\n",
       "      <td>[-0.04940425, 0.436995, -0.203637, -0.09001399...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stemming reduces words to their root form.</td>\n",
       "      <td>[stemming, reduces, words, root, form]</td>\n",
       "      <td>[(stemming, NOUN), (reduces, VERB), (words, NO...</td>\n",
       "      <td>[[tensor(0.7884), tensor(-0.2981), tensor(0.21...</td>\n",
       "      <td>[-0.17456861, 0.48956004, 0.07702799, 0.225233...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0      Natural Language Processing is evolving fast.   \n",
       "1     NLP helps computers understand human language.   \n",
       "2          Text classification is a key task in NLP.   \n",
       "3  Tokenization is the first step in most NLP pip...   \n",
       "4         Stemming reduces words to their root form.   \n",
       "\n",
       "                                              tokens  \\\n",
       "0    [natural, language, processing, evolving, fast]   \n",
       "1  [nlp, helps, computers, understand, human, lan...   \n",
       "2             [text, classification, key, task, nlp]   \n",
       "3               [tokenization, step, nlp, pipelines]   \n",
       "4             [stemming, reduces, words, root, form]   \n",
       "\n",
       "                                             POS_Tag  \\\n",
       "0  [(natural, ADJ), (language, NOUN), (processing...   \n",
       "1  [(nlp, PROPN), (helps, VERB), (computers, NOUN...   \n",
       "2  [(text, NOUN), (classification, NOUN), (key, A...   \n",
       "3  [(tokenization, NOUN), (step, NOUN), (nlp, PRO...   \n",
       "4  [(stemming, NOUN), (reduces, VERB), (words, NO...   \n",
       "\n",
       "                                       glove_vectors  \\\n",
       "0  [[tensor(0.4399), tensor(1.1951), tensor(0.702...   \n",
       "1  [[tensor(-0.4242), tensor(1.1379), tensor(-0.5...   \n",
       "2  [[tensor(-0.4970), tensor(0.7164), tensor(0.40...   \n",
       "3  [[tensor(-0.3844), tensor(-0.1395), tensor(-0....   \n",
       "4  [[tensor(0.7884), tensor(-0.2981), tensor(0.21...   \n",
       "\n",
       "                                           glove_avg  label  \n",
       "0  [-0.003268391, 0.592868, 0.33463138, 0.2203791...      0  \n",
       "1  [-0.031687822, 0.58213, 0.24518669, 0.05667926...      1  \n",
       "2  [-0.43756, 0.5182328, 0.295148, -0.0667942, 0....      0  \n",
       "3  [-0.04940425, 0.436995, -0.203637, -0.09001399...      1  \n",
       "4  [-0.17456861, 0.48956004, 0.07702799, 0.225233...      0  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b69ad75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenzier = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c3a2cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence2 = text[0]\n",
    "inputs = tokenzier(sentence2,return_tensors = 'pt')\n",
    "output = model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "52165af2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 7, 768])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = output.last_hidden_state\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4d4b8240",
   "metadata": {},
   "outputs": [],
   "source": [
    "## BART BIDIRECTIONAL AUTO REGRESSIVE TRANSFORMER "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
